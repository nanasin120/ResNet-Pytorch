# Abstract 초록
아무런 참조 없이 학습하는 대신, 입력 레이어를 참조하여 학습하는 **잔차 학습**을 재구성했다.

이 잔차 네트워크가 최적화하기 더 쉽고, 

층이 깊어져도 정확도가 향상될 수 있음을 보여주는 증거를 제시한다.

이 잔차 학습을 통해 ImageNet에서 성과를 보였다.

표현(특징) 의 깊이는 많은 시각적 인식 작업의 중요한 부분이다.

ResNet의 매우 깊은 표현들로, 여러 성과를 얻었다.

# Introdution
Deep CNN은 이미지 분류에서 일련의 혁신들을 이끌어왔다.

딥 네트워크는 저수준, 중수준, 고수준 레벨의 특징들을 자연스럽게 통합하고 

종단간(끝에서 끝까지)의 다층 방식으로 분류를 하고,

저/중/고수준의 특징들은 쌓인 레이어(깊이)의 수에 따라 강화된다.

최근의 증거는 네트워크의 깊이는 중대한 중요성이고, ImageNet dataset 도전에 따르는 결과는 모두 '매우 깊은' 모델, 16에서 30정도의 깊이' 에서 폭팔했다.
